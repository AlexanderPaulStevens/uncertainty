{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d735f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compact-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "def regression_heteroscedastic_loss(true, mean, log_var, metric): \n",
    "    '''\n",
    "    ARGUMENTS:\n",
    "    true: true values. Tensor (batch_size x number of outputs)\n",
    "    mean: predictions. Tensor (batch_size x number of outputs)\n",
    "    log_var: Logaritms of uncertainty estimates. Tensor (batch_size x number of outputs)\n",
    "    metric: \"mae\" or \"rmse\"\n",
    "\n",
    "    OUTPUTS:\n",
    "    loss: Tensor (0)\n",
    "    '''\n",
    "    precision = torch.exp(-log_var)\n",
    "    if metric == \"mae\":\n",
    "        return torch.mean(torch.sum((2 * precision) ** .5 * torch.abs(true - mean) + log_var / 2, 1), 0)\n",
    "    elif metric == \"rmse\" or not metric:   #default is rmse\n",
    "        return torch.mean(torch.sum(precision * (true - mean) ** 2 + log_var, 1), 0)\n",
    "    else:\n",
    "        print(\"Metric has to be 'rmse' or 'mae'\")\n",
    "\n",
    "def regression_homoscedastic_loss(true, mean, metric):\n",
    "    '''\n",
    "    ARGUMENTS:\n",
    "    true: true values. Tensor (batch_size x number of outputs)\n",
    "    mean: predictions. Tensor (batch_size x number of outputs)\n",
    "    metric: \"mae\" or \"rmse\"\n",
    "\n",
    "    OUTPUTS:\n",
    "    loss: Tensor (0)\n",
    "    '''\n",
    "    \n",
    "    if metric == \"mae\":\n",
    "        return torch.mean(torch.sum(torch.abs(true - mean), 1), 0)\n",
    "    elif metric == \"rmse\" or not metric:   #default is rmse\n",
    "        return torch.mean(torch.sum((true - mean) ** 2, 1), 0)\n",
    "    else:\n",
    "        print(\"Metric has to be 'rmse' or 'mae'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "broad-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "# Adapted from https://github.com/kyle-dorman/bayesian-neural-network-blogpost\n",
    "def classif_heterosc_loss_dorman(pred, true, logvar, T):\n",
    "    '''\n",
    "    ARGUMENTS:\n",
    "    true: true values. Tensor (batch_size x number of outputs)\n",
    "    pred: predictions. Tensor (batch_size x number of outputs)\n",
    "    log_var: Logaritms of uncertainty estimates. Tensor (batch_size x number of outputs)\n",
    "    T: number of forward passes throught the softmax function: Integer\n",
    "\n",
    "    OUTPUTS:\n",
    "    loss: Tensor (0)\n",
    "    '''\n",
    "    CEL_undistort = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    LSM = torch.nn.LogSoftmax(dim=1)\n",
    "    softmax_pred = LSM(pred)\n",
    "    NLLL = torch.nn.NLLLoss(reduction='none')\n",
    "    CEL_loss_undistort = NLLL(softmax_pred, true.long())\n",
    "\n",
    "    std = torch.squeeze(torch.sqrt(torch.exp(logvar)))\n",
    "    variance_depressor = torch.mean(torch.exp(torch.square(std)) - torch.ones(std.size()).cuda(),0)\n",
    "    dim = list(std.size())[0]\n",
    "    std = torch.transpose(std.expand(dim,dim), 0, 1)\n",
    "    cum_elu = 0\n",
    "    for t in range(T):\n",
    "        noise = torch.randn_like(pred)\n",
    "        noisy_pred = pred + torch.matmul(std, noise)\n",
    "        LSM_noisy = torch.nn.LogSoftmax(dim=1)\n",
    "        softmax_noisy_pred = LSM_noisy(noisy_pred)\n",
    "        NLLL_noisy = torch.nn.NLLLoss(reduction='none')\n",
    "        CEN_t = NLLL_noisy(softmax_pred, true.long())\n",
    "\n",
    "        difference = CEN_t  - CEL_loss_undistort\n",
    "        ELU = torch.nn.ELU(alpha=1)\n",
    "        elu = ELU(difference)\n",
    "        cum_elu += elu\n",
    "    loss = torch.mean(CEL_loss_undistort * (1+cum_elu / t),0) + variance_depressor\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8e7111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
